{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eca2e62-ef87-41d5-aca5-a7ce1fe02421",
   "metadata": {},
   "source": [
    "# Image files for animation of COWVR EDR wind speed data during first year of operation\n",
    "\n",
    "This notebook demonstrates plotting daily images of COWVR EDR wind speed - each image includes all satellite passes for that day. The COWVR data are accessed using the `earthaccess()` package (data are \"streamed\" via `xarray`), and the notebook is written such that it will work both on a local machine or in the cloud. That being said, at the time this notebook was written, streaming COWVR data from a local machine via `xarray` was much slower than direct cloud access.\n",
    "\n",
    "#### Additional required files\n",
    "The following image files need to be in the same directory as this notebook:\n",
    "```\n",
    "bluemarble.png\n",
    "nasa_jpl_logo_0.png\n",
    "podaac_logo_B_color.png\n",
    "```\n",
    "\n",
    "#### Optional parallel computation section\n",
    "If the user wishes to generate images for the entire year, this involves processing ~8,500 files at ~1 TB total. This can be run in serial, but would take a projected 9 - 12 hours (at least at the time this notebook was written). Therefore, there is an optional parallel computing section, which will process the files on a local cluster. We used an AWS EC2 instance type `m6i.4xlarge`, which has 16 vCPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a09547d1-c6a0-44fb-ba67-9186246b9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built in packages\n",
    "import os\n",
    "import gc\n",
    "import pathlib\n",
    "import datetime\n",
    "\n",
    "# Packages for math and scientific computing\n",
    "import earthaccess\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Plotting packages\n",
    "import cartopy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f4b08-73d5-4ff8-a059-b8dba0d9e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: parallel computing packages\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00885ecb-ff28-4159-ace3-14a4564c2fc5",
   "metadata": {},
   "source": [
    "### Define data analysis / plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c1d0bf5-8af5-4fb9-a185-353d2cfdb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates image for 1 day of data:\n",
    "def plot_1day(date, outputdir=\"./\", ancillary_images=None):\n",
    "\n",
    "    img_podaac = ancillary_images['img_podaac']\n",
    "    img_nasa = ancillary_images['img_nasa']\n",
    "    img_bluemarble = ancillary_images['img_bluemarble']\n",
    "    \n",
    "    \n",
    "    # File-like objects for all files within the date range:\n",
    "    earthaccess.login()\n",
    "    gran_info = earthaccess.search_data(\n",
    "        short_name = \"COWVR_STPH8_L2_EDR_V9.0\", \n",
    "        cloud_hosted = True,\n",
    "        temporal=(date+\"T00:00:00\", date+\"T23:59:59\"),\n",
    "        )\n",
    "    if len(gran_info)==0:\n",
    "        return # skip this date if no granules available\n",
    "    fileobjs = earthaccess.open(gran_info)\n",
    "    #return fileobjs    # for testing coiled errors\n",
    "    \n",
    "\n",
    "    # Setup plotting axes with blue-marble background:\n",
    "    plt.style.use('dark_background')\n",
    "    fig=plt.figure(figsize=(16, 9), dpi=150)\n",
    "    ax1 = plt.axes([0., 0.15, 0.999, 0.725], projection=cartopy.crs.PlateCarree())\n",
    "    ax1.set_global()\n",
    "    img_extent = (-180, 180, -90, 90)\n",
    "    ax1.imshow(img_bluemarble, origin='upper', extent=img_extent, transform=cartopy.crs.PlateCarree(), zorder=-10)\n",
    "\n",
    "    \n",
    "    # Plot all orbits for the day:\n",
    "    cmap_new = truncate_colormap(plt.get_cmap('cubehelix'), minval=0.075, maxval=0.75) # Adjust bounds on colormap slightly, see function below.\n",
    "    for f in fileobjs[:]:\n",
    "        envvars = xr.open_dataset(f, group='EnvDataRecords', phony_dims='access') # phony_dims kwarg needed for S3 access of this data set.\n",
    "        geoloc = xr.open_dataset(f, group='GriddedGeolocationAndFlags', phony_dims='access')\n",
    "\n",
    "        wspd_qc = envvars['wind_speed'].where((envvars['wind_speed_flag']==0)) # Apply QC flag\n",
    "        pcm = ax1.pcolormesh(\n",
    "            geoloc['grid_lon'], geoloc['grid_lat'], wspd_qc, \n",
    "            cmap=cmap_new, vmin=0, vmax=20, transform=cartopy.crs.PlateCarree()\n",
    "            )\n",
    "        \n",
    "        del envvars, geoloc, wspd_qc\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    # Add title, labels, colobar:\n",
    "    fig.text(\n",
    "        0.5, 0.98, \"Wind Speed from COWVR EDR Level 2 Product, First Year of Operation\", \n",
    "        ha='center', va='top', fontsize=20, fontweight='bold'\n",
    "        )\n",
    "    ax1.set_title(date, fontsize=18, fontweight='bold')\n",
    "    position=fig.add_axes([0.34,0.07,0.33,0.02])  ## the parameters are the specified position you set\n",
    "    cb = fig.colorbar(pcm, cax=position, orientation='horizontal', extend='max')\n",
    "    cb.ax.set_title(\"wind speed (m/s)\", fontsize=18, fontweight='bold')\n",
    "    cb.ax.tick_params(axis='x', which='major', labelsize=14)\n",
    "\n",
    "\n",
    "    # Add logos:\n",
    "        # NASA:\n",
    "    ax2 = plt.axes([0.85, 0.01, 0.1, 0.1])\n",
    "    ax2.set_yticklabels([])\n",
    "    ax2.set_xticklabels([])\n",
    "    ax2.get_xaxis().set_visible(False)\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    ax2.set_axis_off()\n",
    "    ax2.imshow(img_nasa)\n",
    "        # PO.DAAC:\n",
    "    ax3 = plt.axes([0.91, 0.01, 0.1, 0.1])\n",
    "    ax3.set_yticklabels([])\n",
    "    ax3.set_xticklabels([])\n",
    "    ax3.get_xaxis().set_visible(False)\n",
    "    ax3.get_yaxis().set_visible(False)\n",
    "    ax3.set_axis_off()\n",
    "    ax3.imshow(img_podaac)\n",
    "\n",
    "    # method 1:\n",
    "    fig.savefig(outputdir + \"COWVR_STPH8_L2_EDR_V9.0_\" + date + \".jpg\")\n",
    "    plt.close(fig)\n",
    "    del fig, ax1, ax2, ax3, img_podaac, img_nasa, img_bluemarble\n",
    "    gc.collect()\n",
    "\n",
    "    # method 2:\n",
    "    #plt.close(fig)\n",
    "    #return fig\n",
    "\n",
    "    # method 3:\n",
    "    #fname_img = outputdir + \"COWVR_STPH8_L2_EDR_V9.0_\" + date + \".jpg\"\n",
    "    #fig.savefig(fname_img)\n",
    "    #plt.close(fig)\n",
    "    #del fig\n",
    "    #image = open(fname_img, 'rb').read()\n",
    "    #pathlib.Path.unlink(fname_img)\n",
    "    #return image\n",
    "\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70ae0f-d80f-4ef9-a195-352a9c8d199d",
   "metadata": {},
   "source": [
    "### Some prep work before running the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "074caf20-4b2d-4f9f-a276-86cf9e5cc1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<earthaccess.auth.Auth at 0x7fbfa0848ad0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthaccess.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a047c0ed-e921-4ca1-a8b5-a3e217af9c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n",
      "['2022-01-08', '2022-01-09', '2022-01-10', '2022-01-11', '2022-01-12', '2022-01-13', '2022-01-14', '2022-01-15', '2022-01-16', '2022-01-17']\n"
     ]
    }
   ],
   "source": [
    "# Generate list of strings for all dates to create images for (year 2022):\n",
    "d1 = datetime.date(2022, 1, 8)\n",
    "d2 = datetime.date(2022, 12, 31)\n",
    "dates_2022 = [d1 + datetime.timedelta(days=x) for x in range((d2-d1).days + 1)]\n",
    "dates_2022 = [d.strftime('%Y%m%d') for d in dates_2022]\n",
    "dates_2022 = [d[0:4]+\"-\"+d[4:6]+\"-\"+d[6:8] for d in dates_2022]\n",
    "\n",
    "print(len(dates_2022))\n",
    "print(dates_2022[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23ed36a2-2007-4f2f-b11c-247c2a366b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some ancillary images to include in the figures, includeing a background blue-marble \n",
    "# image behind the data, and NASA/PO.DAAC logos in the corner. This code assumes the files\n",
    "# are in the same folder as this notebook: \n",
    "img_podaac = plt.imread('podaac_logo_B_color.png')\n",
    "img_nasa = plt.imread('nasa_jpl_logo_0.png')\n",
    "img_bluemarble = plt.imread('bluemarble.png')\n",
    "\n",
    "ancillary_images = {'img_podaac':img_podaac, 'img_nasa':img_nasa, 'img_bluemarble':img_bluemarble}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c9125-7489-4397-804d-66eba5ca26f3",
   "metadata": {},
   "source": [
    "### Test the function to create image for a single day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a61d6d82-c3ce-4db6-96af-0c9e621cf654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to save images in:\n",
    "!mkdir animation_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0f34502-4edb-4db0-a5b1-d46e16d2ad82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 22\n",
      "Opening 22 granules, approx size: 2.46 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b83a50d44e841c1a027adbc1304b70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8c4b88d00b44ddaa3ea73e411890c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d902dda2132483abdff20a9cf991ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.6 s, sys: 6.01 s, total: 50.7 s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Image file will be saved to the above directory:\n",
    "_ = plot_1day(dates_2022[0], outputdir=\"./animation_images/\", ancillary_images=ancillary_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c48ce739-e849-4ee8-9ef0-d62f34822d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the image (note that in the actual saved image, the axis tick labels do not appear:\n",
    "img = mpimg.imread(\"./animation_images/COWVR_STPH8_L2_EDR_V9.0_\" + dates_2022[0] + \".jpg\")\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9930c92-0a40-45ad-8067-17ae3846e3b8",
   "metadata": {},
   "source": [
    "### Optional: Parallelize image generation using dask and a local cluster\n",
    "\n",
    "We used an AWS EC2 instance type `m6i.4xlarge`, which has 16 vCPUs. And since there is enough memory per CPU on this instance for our computations, we used 16 workers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba598891-a9d0-4f94-8f78-f709afea261e",
   "metadata": {},
   "source": [
    "First, it is necessary to write a quick authentication function which will be run on each worker, ensuring that they have the same EDL credentials (and therefore NASA Earthdata access), as this notebook (recall we established ours with a call to `earthdata.login()` earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ae014-3e8a-444e-af17-e42277250cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auth_env(auth):\n",
    "    os.environ[\"EARTHDATA_USERNAME\"] = auth[\"EARTHDATA_USERNAME\"]\n",
    "    os.environ[\"EARTHDATA_PASSWORD\"] = auth[\"EARTHDATA_PASSWORD\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb8c76-6b37-4802-bf78-9ee03ebc42a0",
   "metadata": {},
   "source": [
    "Now, a quick detour. Ideally the following code would work. This code starts up a single local cluster with 16 workers, then asks the workers churn through the 358 days. \n",
    "\n",
    "```\n",
    "client = Client(n_workers=16, threads_per_worker=1)\n",
    "client.run(auth_env, auth=earthaccess.auth_environ()) # Get EDL creds on each worker\n",
    "\n",
    "# Process all granules in parallel using Dask\n",
    "plot_1day_delayed = delayed(plot_1day)\n",
    "tasks = [\n",
    "    plot_1day_delayed(d, outputdir=\"./animation_images/\", ancillary_images=ancillary_images) \n",
    "    for d in dates_2022[:] \n",
    "    ]\n",
    "results = da.compute(*tasks)\n",
    "\n",
    "client.close()\n",
    "```\n",
    "\n",
    "\n",
    "However, due to very low level workings of Python (and even lower level languages?), our workers tend not to release all of the memory they used to process one of the days, meaning that as they churn through more and more days, less memory is available until the code crashes. Therefore, we use the following (admittedly very not glamorous) workaround in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd20c5a-1968-4c0c-8bc1-fd91dbcd8982",
   "metadata": {},
   "source": [
    "### Work around for Dask workers accumulating too much memory\n",
    "Instead, we work in batches of 16 files, calling and closing a sepearte local cluster for each batch. This apparently releases the memory fully once the cluster is closed. ***Note that the output for the last block of code is very long, and may be full of warning messages, but for us still completed successfully.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2cb1724b-172b-4de3-bdc7-11a36cbf8335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 16, 32, 48, 64]\n"
     ]
    }
   ],
   "source": [
    "# Index numbers for the batches (used to slice the dates_2022 list):\n",
    "i_list = []\n",
    "i_list.append(0)\n",
    "for x in range(1, int(np.floor(len(dates_2022)/16))):\n",
    "    i_list.append(i_list[-1] + 16)\n",
    "i_list.append(len(dates_2022))\n",
    "print(i_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fac755e0-bc4a-4ad9-8c89-c0ae10745b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 37017 instead\n",
      "  warnings.warn(\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/client.py:3163: UserWarning: Sending large graph of size 126.46 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 22\n",
      "Granules found: 26\n",
      "Granules found: 12\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 24\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 18\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Opening 22 granules, approx size: 2.46 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.84 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 18 granules, approx size: 2.06 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 12 granules, approx size: 1.35 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 24 granules, approx size: 2.75 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1695.85it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 102.04it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 396552.38it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1957.63it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1061.95it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1030.55it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 106.09it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 359907.27it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 110.06it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 276080.77it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 114.63it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 364722.09it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1830.93it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 12/12 [00:00<00:00, 460.91it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 1836.45it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 12/12 [00:00<00:00, 50.06it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 12/12 [00:00<00:00, 227745.01it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.99it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 376041.05it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 95.87it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 209296.61it/s]\n",
      "\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1023.46it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1118.69it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 18/18 [00:00<00:00, 75.03it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 18/18 [00:00<00:00, 195083.91it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 22/22 [00:00<00:00, 690.02it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.58it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 188671.11it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 859.11it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1584.04it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1918.54it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 2172.79it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 91.76it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 265980.25it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 22/22 [00:00<00:00, 77.98it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 22/22 [00:00<00:00, 160757.30it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 605.28it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 77.63it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 222101.64it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 86.53it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 222554.91it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 71.04it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 24/24 [00:00<00:00, 243736.79it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 70.98it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 280339.08it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 82.18it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 269930.46it/s]\n",
      "2024-03-27 20:44:38,167 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:47,498 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:48,265 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.72 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:49,782 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:49,995 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:51,303 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:52,117 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:54,860 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:55,960 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:56,057 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:56,242 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.72 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:56,283 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:56,367 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:57,342 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:57,479 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:57,553 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:58,265 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.72 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:58,322 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:58,851 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:59,089 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:59,131 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:59,808 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:44:59,995 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:00,830 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:01,390 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:02,217 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:02,228 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:02,395 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:02,579 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:02,799 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:02,800 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:02,859 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:02,869 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:03,110 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:03,826 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:03,868 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:04,058 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:04,205 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:04,266 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:04,320 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:04,553 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:04,681 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:04,898 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:04,985 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:05,113 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:06,341 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:06,363 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:06,465 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:06,465 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:06,495 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:07,147 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38508 remote=tcp://127.0.0.1:41549>: Stream is closed\n",
      "2024-03-27 20:45:07,248 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38514 remote=tcp://127.0.0.1:41549>: Stream is closed\n",
      "2024-03-27 20:45:07,350 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38544 remote=tcp://127.0.0.1:41549>: Stream is closed\n",
      "2024-03-27 20:45:07,356 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:07,452 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38612 remote=tcp://127.0.0.1:41549>: Stream is closed\n",
      "2024-03-27 20:45:07,518 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:07,553 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38494 remote=tcp://127.0.0.1:41549>: Stream is closed\n",
      "2024-03-27 20:45:07,654 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:45:07,756 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38570 remote=tcp://127.0.0.1:41549>: Stream is closed\n",
      "2024-03-27 20:45:07,756 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38538 remote=tcp://127.0.0.1:41549>: Stream is closed\n",
      "2024-03-27 20:45:07,859 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38590 remote=tcp://127.0.0.1:41549>: Stream is closed\n",
      "2024-03-27 20:45:07,961 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38616 remote=tcp://127.0.0.1:41549>: Stream is closed\n",
      "2024-03-27 20:45:08,063 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38618 remote=tcp://127.0.0.1:41549>: Stream is closed\n",
      "2024-03-27 20:45:08,064 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38602 remote=tcp://127.0.0.1:41549>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 35087 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 21\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 24\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 24\n",
      "Granules found: 26\n",
      "Granules found: 18\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 24 granules, approx size: 2.75 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GBOpening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 18 granules, approx size: 2.07 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 21 granules, approx size: 2.41 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 24 granules, approx size: 2.76 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1066.98it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 18/18 [00:00<00:00, 811.28it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1826.54it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 103.39it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 385342.42it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 18/18 [00:00<00:00, 80.01it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 18/18 [00:00<00:00, 238162.37it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 1008.14it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 996.41it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 105.60it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 393689.18it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 906.70it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 21/21 [00:00<00:00, 792.67it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 965.61it/s]\n",
      "PROCESSING TASKS | :   4%|▍         | 1/26 [00:00<00:04,  5.47it/s]]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 754.48it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 102.21it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 24/24 [00:00<00:00, 336666.54it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1540.09it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.22it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 313367.54it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 97.51it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 275941.05it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1233.59it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1080.11it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 102.78it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 264689.09it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 546.34it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 90.10it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 276781.48it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 691.73it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 85.75it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 265333.10it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 21/21 [00:00<00:00, 48.50it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 21/21 [00:00<00:00, 253104.55it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 82.79it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 286978.69it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 90.45it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 242877.29it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 74.56it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 345100.96it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 72.06it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 24/24 [00:00<00:00, 262828.45it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.17it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 269263.96it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 500.48it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 84.85it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 282517.89it/s]\n",
      "2024-03-27 20:47:09,444 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:22,355 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:25,429 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:26,684 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:30,302 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.72 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:30,585 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:31,081 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:31,215 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:32,234 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:32,355 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:32,635 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:32,965 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:33,009 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:33,131 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:33,751 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:33,932 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:33,973 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:34,040 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:34,105 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:34,172 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:34,372 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:34,800 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:34,828 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:35,498 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:36,772 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:37,083 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:37,721 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:38,123 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:38,182 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:38,257 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:38,383 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:39,041 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:39,305 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:39,537 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:39,691 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:40,078 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:40,312 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:40,391 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:40,403 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:40,681 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:40,855 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:41,179 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:41,216 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:41,302 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:41,444 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:42,332 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:42,454 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:42,684 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:42,833 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:43,012 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:43,230 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:47:43,480 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46404 remote=tcp://127.0.0.1:38823>: Stream is closed\n",
      "2024-03-27 20:47:43,683 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46446 remote=tcp://127.0.0.1:38823>: Stream is closed\n",
      "2024-03-27 20:47:43,684 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46420 remote=tcp://127.0.0.1:38823>: Stream is closed\n",
      "2024-03-27 20:47:43,785 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46394 remote=tcp://127.0.0.1:38823>: Stream is closed\n",
      "2024-03-27 20:47:43,887 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46462 remote=tcp://127.0.0.1:38823>: Stream is closed\n",
      "2024-03-27 20:47:43,989 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46336 remote=tcp://127.0.0.1:38823>: Stream is closed\n",
      "2024-03-27 20:47:44,090 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46364 remote=tcp://127.0.0.1:38823>: Stream is closed\n",
      "2024-03-27 20:47:44,193 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46362 remote=tcp://127.0.0.1:38823>: Stream is closed\n",
      "2024-03-27 20:47:44,395 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46350 remote=tcp://127.0.0.1:38823>: Stream is closed\n",
      "2024-03-27 20:47:44,395 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46314 remote=tcp://127.0.0.1:38823>: Stream is closed\n",
      "2024-03-27 20:47:44,397 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46436 remote=tcp://127.0.0.1:38823>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42975 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.87 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 1.8 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1215.05it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1236.77it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 991.25it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 1746.26it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 908.23it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 113.99it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 376041.05it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 854.67it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 107.63it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 293940.44it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 114.47it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 297144.15it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 113.46it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 344012.32it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 106.05it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 247890.31it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 803.26it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 876.31it/s]\n",
      "QUEUEING TASKS | :   0%|          | 0/26 [00:00<?, ?it/s]620.29it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 725.21it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 687.18it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 935.56it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 108.38it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 210932.12it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 607.95it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 574.80it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 669.97it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 418.84it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 80.84it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 264048.19it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.62it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 359907.27it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 84.83it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 219862.71it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 76.06it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 269930.46it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 79.05it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 264048.19it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 72.16it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 286225.47it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 95.24it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 233515.85it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 90.66it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 376041.05it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 64.54it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 260889.72it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 76.68it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 235533.27it/s]\n",
      "2024-03-27 20:49:33,187 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:49:40,593 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:49:43,287 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.11 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:49:53,387 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.11 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:49:57,888 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:03,486 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.11 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:03,766 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:04,449 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:05,092 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:05,239 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:05,303 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:06,002 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:06,206 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:06,237 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:06,437 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:07,937 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:08,198 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:08,427 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:08,531 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:08,551 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:08,704 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:08,832 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:09,432 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:11,148 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:11,931 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:12,602 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:12,620 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:12,633 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:12,647 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:12,744 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:13,011 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:13,141 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:13,487 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.11 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:13,715 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:14,477 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:14,738 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:15,093 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:15,105 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:15,132 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:15,271 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:15,784 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:16,385 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:16,409 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:16,582 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:16,684 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:16,685 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:16,854 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:16,879 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:17,268 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:17,937 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:18,428 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:18,524 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:18,568 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:18,571 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:18,706 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:18,873 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:18,893 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:19,519 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:19,934 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:21,227 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:21,242 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:21,247 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:21,290 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:21,306 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:50:21,930 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38762 remote=tcp://127.0.0.1:39709>: Stream is closed\n",
      "2024-03-27 20:50:22,031 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38776 remote=tcp://127.0.0.1:39709>: Stream is closed\n",
      "2024-03-27 20:50:22,132 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38724 remote=tcp://127.0.0.1:39709>: Stream is closed\n",
      "2024-03-27 20:50:22,234 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38800 remote=tcp://127.0.0.1:39709>: Stream is closed\n",
      "2024-03-27 20:50:22,335 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38746 remote=tcp://127.0.0.1:39709>: Stream is closed\n",
      "2024-03-27 20:50:22,437 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38832 remote=tcp://127.0.0.1:39709>: Stream is closed\n",
      "2024-03-27 20:50:22,641 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38810 remote=tcp://127.0.0.1:39709>: Stream is closed\n",
      "2024-03-27 20:50:22,641 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38792 remote=tcp://127.0.0.1:39709>: Stream is closed\n",
      "2024-03-27 20:50:22,742 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38862 remote=tcp://127.0.0.1:39709>: Stream is closed\n",
      "2024-03-27 20:50:22,844 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38858 remote=tcp://127.0.0.1:39709>: Stream is closed\n",
      "2024-03-27 20:50:22,846 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:38872 remote=tcp://127.0.0.1:39709>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 46581 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 24\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 21\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.91 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.87 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.87 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.87 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 21 granules, approx size: 2.39 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 24 granules, approx size: 2.65 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 1891.37it/s]\n",
      "PROCESSING TASKS | :   4%|▍         | 1/25 [00:00<00:04,  5.16it/s]]\n",
      "QUEUEING TASKS | : 100%|██████████| 21/21 [00:00<00:00, 841.52it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 102.55it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 404855.60it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1563.04it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 1677.05it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 982.39it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1113.62it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1690.28it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1269.82it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 795.20it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1168.44it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 109.20it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 257805.92it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 21/21 [00:00<00:00, 89.48it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 21/21 [00:00<00:00, 136983.49it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 822.08it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 877.05it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 86.99it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 246723.76it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 83.96it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 24/24 [00:00<00:00, 296068.52it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 826.60it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 92.52it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 274689.93it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 87.11it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 293150.28it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 84.80it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 290805.08it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 79.87it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 235533.27it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 81.51it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 256375.55it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 88.54it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 335544.32it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 90.53it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 290031.66it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 90.41it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 261515.36it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 94.37it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 284730.82it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 355.46it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 85.28it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 365357.49it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1564.95it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 86.65it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 235025.66it/s]\n",
      "2024-03-27 20:52:25,515 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.72 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:35,192 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:38,069 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:38,140 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:41,420 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:42,091 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:43,367 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:43,708 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:44,220 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:44,298 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:44,544 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:45,112 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:45,291 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:45,301 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:45,950 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:46,699 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:47,105 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:47,442 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:48,151 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:48,682 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:48,718 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:48,783 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:49,519 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:49,722 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:50,158 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:50,349 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:50,453 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:50,489 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:50,921 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.11 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:51,039 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:51,458 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:51,494 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:51,517 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:51,873 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:51,998 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:52,091 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:52,198 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:52,401 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:52,555 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:52,662 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:53,458 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:53,465 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:53,809 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:53,887 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:54,221 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:54,285 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:54,299 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:54,545 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:54,723 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:55,085 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:55,162 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:55,292 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:55,302 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:56,009 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:56,087 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.11 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:57,105 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:57,802 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:57,804 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:57,807 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:57,818 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:57,833 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:57,843 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:57,848 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:57,858 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:57,861 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:57,866 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:57,869 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:58,169 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:52:58,184 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39108 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:58,286 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39172 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:58,388 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39092 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:58,489 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39086 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:58,692 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39160 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:58,692 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39122 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:58,794 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39144 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:58,895 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39116 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:58,996 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39150 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:59,098 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39206 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:59,200 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39186 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:59,402 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39164 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:59,403 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39194 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "2024-03-27 20:52:59,405 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:39218 remote=tcp://127.0.0.1:44143>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 37955 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 9\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 5\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 24\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Opening 9 granules, approx size: 0.92 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.87 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 24 granules, approx size: 2.76 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.92 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 0.52 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.62 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 5 granules, approx size: 0.57 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.87 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1058.12it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1022.07it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 105.85it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 354064.62it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 9/9 [00:00<00:00, 409.36it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 108.88it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 363506.35it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 2213.65it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 923.75it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 781.10it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 9/9 [00:00<00:00, 44.29it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 9/9 [00:00<00:00, 200791.15it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 93.11it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 24/24 [00:00<00:00, 302292.18it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.73it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 369667.47it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 94.82it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 322638.77it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 1418.60it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 105.56it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 355449.49it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 934.62it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 924.13it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 2034.78it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 5/5 [00:00<00:00, 457.25it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 909.96it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 910.16it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 875.12it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 99.12it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 259647.39it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 893.75it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1337.95it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.28it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 165732.38it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 5/5 [00:00<00:00, 24.58it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 5/5 [00:00<00:00, 86659.17it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 89.15it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 339725.56it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 91.56it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 373465.42it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.35it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 254794.17it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 91.18it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 184284.01it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 86.27it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 271273.39it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 90.58it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 273313.04it/s]\n",
      "2024-03-27 20:54:10,824 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:54:16,664 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:54:20,832 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:54:30,932 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:54:40,933 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:54:51,033 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:01,132 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:08,494 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:08,780 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:11,234 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:14,257 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:15,626 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:16,676 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:18,495 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:18,877 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:19,207 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:20,336 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:20,376 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:21,140 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:21,332 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:21,593 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:22,089 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:22,520 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:23,927 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:24,159 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:24,258 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:25,036 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:26,368 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:26,676 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:26,803 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:26,911 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:26,963 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:27,303 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:28,275 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:28,298 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:28,311 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:28,594 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:28,737 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:28,811 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:28,976 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:29,208 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:29,259 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:29,311 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:29,351 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:29,727 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:29,915 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:30,018 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:30,377 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:30,434 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:31,162 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:31,431 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:31,834 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:32,110 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:32,615 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:32,758 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:33,951 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,065 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,075 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,076 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,093 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 2.99 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,108 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,111 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,133 - distributed.worker.memory - WARNING - Worker is at 77% memory usage. Resuming worker. Process memory: 2.97 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,135 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,137 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,150 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,157 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 2.99 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,356 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.99 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:34,773 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56674 remote=tcp://127.0.0.1:34165>: Stream is closed\n",
      "2024-03-27 20:55:34,875 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56726 remote=tcp://127.0.0.1:34165>: Stream is closed\n",
      "2024-03-27 20:55:34,976 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56710 remote=tcp://127.0.0.1:34165>: Stream is closed\n",
      "2024-03-27 20:55:35,137 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:55:35,178 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56802 remote=tcp://127.0.0.1:34165>: Stream is closed\n",
      "2024-03-27 20:55:35,179 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56746 remote=tcp://127.0.0.1:34165>: Stream is closed\n",
      "2024-03-27 20:55:35,280 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56722 remote=tcp://127.0.0.1:34165>: Stream is closed\n",
      "2024-03-27 20:55:35,381 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56782 remote=tcp://127.0.0.1:34165>: Stream is closed\n",
      "2024-03-27 20:55:35,483 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56762 remote=tcp://127.0.0.1:34165>: Stream is closed\n",
      "2024-03-27 20:55:35,584 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56772 remote=tcp://127.0.0.1:34165>: Stream is closed\n",
      "2024-03-27 20:55:35,686 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56786 remote=tcp://127.0.0.1:34165>: Stream is closed\n",
      "2024-03-27 20:55:35,687 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:56692 remote=tcp://127.0.0.1:34165>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 39161 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 9\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 9 granules, approx size: 1.03 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.96 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.96 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1839.42it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 9/9 [00:00<00:00, 350.66it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1006.93it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 999.00it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1446.50it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 9/9 [00:00<00:00, 43.42it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 9/9 [00:00<00:00, 154076.47it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.77it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 373465.42it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1138.67it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1691.17it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 109.84it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 382638.26it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 111.98it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 340787.20it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 91.55it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 317935.58it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 110.21it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 246723.76it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 901.95it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 88.99it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 292364.35it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 96.00it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 308056.23it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1013.47it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 92.15it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 286225.47it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1056.38it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 110.32it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 369667.47it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1451.59it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 963.55it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1406.34it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 941.50it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 964.17it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1469.96it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 88.10it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 366634.97it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 87.50it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 312469.64it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 102.39it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 106184.91it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 90.21it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 284730.82it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 85.23it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 271949.89it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 77.90it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 319800.30it/s]\n",
      "2024-03-27 20:57:52,887 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:57:53,334 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:57:53,344 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:57:56,833 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:57:56,859 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:57:56,973 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:57:57,363 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:57:59,306 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:57:59,598 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:57:59,682 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:57:59,691 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:57:59,842 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:57:59,957 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:00,596 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:02,059 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:02,247 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:02,573 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:03,123 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:03,509 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:03,750 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:03,880 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:04,719 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:04,794 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:05,726 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:06,391 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:06,463 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:06,735 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:06,763 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:06,915 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.15 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:06,924 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:06,937 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:06,974 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:07,127 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:07,379 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:07,464 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:07,546 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:07,795 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:07,969 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:08,008 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:08,208 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:08,334 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:08,356 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:08,385 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:08,419 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:08,453 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:09,468 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:09,511 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:09,598 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.22 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:09,683 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.21 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:09,691 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:09,891 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:09,957 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:10,662 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,255 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,262 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,272 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,282 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,286 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,291 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,291 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,298 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,306 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,316 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,323 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,324 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 2.99 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,334 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:11,344 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 20:58:12,066 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37276 remote=tcp://127.0.0.1:42723>: Stream is closed\n",
      "2024-03-27 20:58:12,166 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37246 remote=tcp://127.0.0.1:42723>: Stream is closed\n",
      "2024-03-27 20:58:12,269 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37260 remote=tcp://127.0.0.1:42723>: Stream is closed\n",
      "2024-03-27 20:58:12,370 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37358 remote=tcp://127.0.0.1:42723>: Stream is closed\n",
      "2024-03-27 20:58:12,473 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37348 remote=tcp://127.0.0.1:42723>: Stream is closed\n",
      "2024-03-27 20:58:12,575 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37258 remote=tcp://127.0.0.1:42723>: Stream is closed\n",
      "2024-03-27 20:58:12,778 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37292 remote=tcp://127.0.0.1:42723>: Stream is closed\n",
      "2024-03-27 20:58:12,778 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37304 remote=tcp://127.0.0.1:42723>: Stream is closed\n",
      "2024-03-27 20:58:12,879 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37294 remote=tcp://127.0.0.1:42723>: Stream is closed\n",
      "2024-03-27 20:58:12,880 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37374 remote=tcp://127.0.0.1:42723>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 33829 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 12\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 6\n",
      "Granules found: 4\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 12 granules, approx size: 1.37 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 6 granules, approx size: 0.69 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 4 granules, approx size: 0.46 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.93 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 4/4 [00:00<00:00, 435.15it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1009.81it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 6/6 [00:00<00:00, 535.56it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 968.76it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 977.89it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1069.36it/s]\n",
      "QUEUEING TASKS | :   0%|          | 0/26 [00:00<?, ?it/s]293.63it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 1638.76it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 866.74it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 4/4 [00:00<00:00, 21.19it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 4/4 [00:00<00:00, 78398.21it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 880.49it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.90it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 281787.87it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 6/6 [00:00<00:00, 28.71it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 6/6 [00:00<00:00, 67108.86it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 108.75it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 314270.62it/s]\n",
      "QUEUEING TASKS | :   0%|          | 0/26 [00:00<?, ?it/s]04.72it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.47it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 266630.57it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 680.35it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 108.75it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 386708.88it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 88.23it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 276080.77it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 93.54it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 270949.87it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 86.61it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 221650.21it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 627.07it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 2295.49it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 619.78it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 91.24it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 255750.24it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 12/12 [00:00<00:00, 43.24it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 102.43it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 12/12 [00:00<00:00, 178481.02it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 274689.93it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 92.53it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 271949.89it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.51it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 253609.08it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 71.88it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 362298.68it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1089.01it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 98.17it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 377342.23it/s]\n",
      "2024-03-27 21:00:26,191 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:29,192 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:30,590 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:30,652 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:32,044 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:32,589 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:32,628 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:32,632 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:34,767 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:34,920 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:35,046 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:35,246 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:35,813 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:36,293 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:36,353 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:36,518 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:37,679 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:39,221 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:39,452 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:39,598 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:39,783 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:39,933 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:39,962 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:39,978 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:40,282 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:40,699 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:40,779 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:42,143 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:42,238 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:42,244 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:42,484 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:42,590 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:42,632 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:42,675 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:42,732 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:42,841 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:43,244 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:43,672 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:43,969 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:44,366 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:44,775 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 2.99 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:44,835 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:44,921 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:45,144 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:45,813 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:46,354 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:46,390 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:47,020 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:47,030 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:47,045 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:47,054 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:00:47,401 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51680 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:47,603 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51786 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:47,603 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51704 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:47,705 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51794 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:47,806 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51802 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:47,908 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51688 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:48,011 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51686 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:48,112 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51742 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:48,214 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51724 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:48,316 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51788 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:48,418 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51720 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:48,521 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51762 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:48,623 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51752 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "2024-03-27 21:00:48,625 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51766 remote=tcp://127.0.0.1:36107>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 38393 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 24\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Opening 26 granules, approx size: 2.73 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 25\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 24 granules, approx size: 2.74 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.89 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.85 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.9 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1778.73it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1027.32it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1046.30it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1022.77it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1053.51it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 2485.46it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 105.92it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 290031.66it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 106.72it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 295533.62it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 857.99it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 107.53it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 278193.63it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1719.06it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 104.85it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 288497.10it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.48it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 392273.04it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 1052.18it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 107.09it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 282517.89it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1441.06it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 102.11it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 223467.02it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 769.77it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 776.49it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 521.22it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 579.43it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 372.75it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 93.66it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 283251.70it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 287.45it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 73.95it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 24/24 [00:00<00:00, 274286.91it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 88.26it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 172277.89it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 81.56it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 280339.08it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 79.77it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 268178.01it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 84.25it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 295373.52it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 87.37it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 286225.47it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 74.88it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 261490.27it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 93.51it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 278905.13it/s]\n",
      "2024-03-27 21:03:06,850 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:08,284 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:10,075 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:12,769 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:13,165 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.72 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:13,494 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:13,913 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:14,653 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:15,168 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:15,896 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:16,339 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:16,440 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:16,449 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:16,551 - distributed.worker.memory - WARNING - Worker is at 82% memory usage. Pausing worker.  Process memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:16,866 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:16,866 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:18,255 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:18,384 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:18,439 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:18,482 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:18,671 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:18,984 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:20,236 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:20,421 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:21,642 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:21,982 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:21,994 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:22,083 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:22,115 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:22,623 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:22,811 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:23,332 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:23,343 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:23,496 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:23,578 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:24,011 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:24,242 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:24,772 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:25,092 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:25,129 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:25,209 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:25,333 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:25,922 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:25,992 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:26,241 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:26,385 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:26,511 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:26,530 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:26,950 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:27,456 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:28,255 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:28,483 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:28,539 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:28,577 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:28,772 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:30,218 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48314 remote=tcp://127.0.0.1:42325>: Stream is closed\n",
      "2024-03-27 21:03:30,320 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48306 remote=tcp://127.0.0.1:42325>: Stream is closed\n",
      "2024-03-27 21:03:30,335 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:30,474 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:03:30,523 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48366 remote=tcp://127.0.0.1:42325>: Stream is closed\n",
      "2024-03-27 21:03:30,523 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48394 remote=tcp://127.0.0.1:42325>: Stream is closed\n",
      "2024-03-27 21:03:30,624 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48342 remote=tcp://127.0.0.1:42325>: Stream is closed\n",
      "2024-03-27 21:03:30,726 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48318 remote=tcp://127.0.0.1:42325>: Stream is closed\n",
      "2024-03-27 21:03:30,828 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48374 remote=tcp://127.0.0.1:42325>: Stream is closed\n",
      "2024-03-27 21:03:30,829 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:48418 remote=tcp://127.0.0.1:42325>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 33891 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.81 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1204.57it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1001.13it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 968.39it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1913.22it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1022.93it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 985.22it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 953.33it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 82.22it/s] \n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 323596.15it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 75.84it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 290031.66it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 73.88it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 323596.15it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1133.55it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 72.02it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 328469.59it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 79.54it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 355217.93it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 70.27it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 311576.87it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1004.58it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 77.57it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 266630.57it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1357.50it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 926.26it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1257.88it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1233.21it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 86.56it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 275383.60it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 89.36it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 35661.19it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 79.10it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 248409.80it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 82.28it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 290805.08it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 75.01it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 271949.89it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 70.62it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 250694.03it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 576.60it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 674.70it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 82.33it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 363506.35it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 84.69it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 270600.26it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 840.27it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 94.41it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 364088.89it/s]\n",
      "2024-03-27 21:05:52,966 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:05:56,707 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:05:56,877 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:05:59,086 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:05:59,409 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:00,435 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:01,188 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:01,474 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:01,507 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:01,650 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:02,129 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:02,582 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:02,794 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:02,866 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:03,550 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:05,506 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:05,856 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:06,427 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:06,482 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:06,579 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:06,672 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:06,837 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:07,235 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:07,238 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:07,258 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:07,401 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:07,725 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:08,807 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:09,176 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:09,406 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:09,446 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:09,467 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:09,535 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:09,554 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:09,830 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:09,912 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:09,972 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:10,309 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:10,571 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:10,842 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:10,904 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:11,205 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:11,487 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:11,573 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:11,605 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:11,955 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:12,353 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:12,684 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:12,762 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 2.99 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:12,815 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:13,206 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:13,220 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:13,514 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:13,566 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:13,651 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:14,673 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:15,608 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:15,793 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:15,805 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:15,940 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:16,218 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:16,673 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:16,915 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,279 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,307 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,533 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,538 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,550 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,567 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,572 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,573 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,577 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,578 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,582 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,587 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,598 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,606 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,606 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,607 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:17,615 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:06:18,226 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:57364 remote=tcp://127.0.0.1:44917>: Stream is closed\n",
      "2024-03-27 21:06:18,429 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:57402 remote=tcp://127.0.0.1:44917>: Stream is closed\n",
      "2024-03-27 21:06:18,429 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:57404 remote=tcp://127.0.0.1:44917>: Stream is closed\n",
      "2024-03-27 21:06:18,531 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:57468 remote=tcp://127.0.0.1:44917>: Stream is closed\n",
      "2024-03-27 21:06:18,633 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:57436 remote=tcp://127.0.0.1:44917>: Stream is closed\n",
      "2024-03-27 21:06:18,734 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:57424 remote=tcp://127.0.0.1:44917>: Stream is closed\n",
      "2024-03-27 21:06:18,838 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:57472 remote=tcp://127.0.0.1:44917>: Stream is closed\n",
      "2024-03-27 21:06:18,940 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:57390 remote=tcp://127.0.0.1:44917>: Stream is closed\n",
      "2024-03-27 21:06:19,042 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:57452 remote=tcp://127.0.0.1:44917>: Stream is closed\n",
      "2024-03-27 21:06:19,143 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:57476 remote=tcp://127.0.0.1:44917>: Stream is closed\n",
      "2024-03-27 21:06:19,144 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:57480 remote=tcp://127.0.0.1:44917>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 36787 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 20\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 24\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 20 granules, approx size: 2.29 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 24 granules, approx size: 2.76 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 20/20 [00:00<00:00, 1530.52it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1045.67it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 997.69it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 942.51it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1135.93it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 952.73it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 897.81it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 20/20 [00:00<00:00, 84.76it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 20/20 [00:00<00:00, 311844.16it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 112.03it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 950.21it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 298772.34it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 109.65it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 326502.71it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 902.08it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 110.62it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 24/24 [00:00<00:00, 280399.15it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1417.11it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 687.73it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1022.12it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1228.73it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 905.42it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 95.99it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 290031.66it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 95.96it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 129669.33it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 89.38it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 276080.77it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.80it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 308928.91it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.72it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 273999.76it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 609.97it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 96.49it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 271949.89it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 77.54it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 267284.08it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 79.01it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 270600.26it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.19it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 280339.08it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 79.92it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 274689.93it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.98it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 253020.66it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 257.41it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 95.42it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 260889.72it/s]\n",
      "2024-03-27 21:08:40,251 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:41,661 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:42,558 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:43,589 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:43,822 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:45,207 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:45,279 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:45,675 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:46,086 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:46,222 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:47,037 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:47,238 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:47,244 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.72 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:48,456 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:48,618 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:50,252 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:50,457 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:51,100 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:51,855 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:52,058 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:52,059 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:52,559 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.15 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:52,679 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:52,707 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:53,343 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:53,901 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:53,926 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:54,025 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:54,386 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:54,570 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:54,588 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:54,853 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:55,072 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:55,223 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:55,278 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:55,365 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:55,455 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:55,965 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:55,986 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:56,117 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:56,152 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:56,154 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:56,186 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.16 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:56,285 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:56,512 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:56,762 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:56,980 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:57,286 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:57,341 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:57,342 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:58,525 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:58,556 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:58,557 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:58,579 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:58,588 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:58,618 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:08:58,848 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47834 remote=tcp://127.0.0.1:44301>: Stream is closed\n",
      "2024-03-27 21:08:59,153 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47828 remote=tcp://127.0.0.1:44301>: Stream is closed\n",
      "2024-03-27 21:08:59,558 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47784 remote=tcp://127.0.0.1:44301>: Stream is closed\n",
      "2024-03-27 21:08:59,559 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47796 remote=tcp://127.0.0.1:44301>: Stream is closed\n",
      "2024-03-27 21:08:59,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47724 remote=tcp://127.0.0.1:44301>: Stream is closed\n",
      "2024-03-27 21:08:59,863 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47822 remote=tcp://127.0.0.1:44301>: Stream is closed\n",
      "2024-03-27 21:08:59,863 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47848 remote=tcp://127.0.0.1:44301>: Stream is closed\n",
      "2024-03-27 21:09:00,066 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47810 remote=tcp://127.0.0.1:44301>: Stream is closed\n",
      "2024-03-27 21:09:00,168 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47798 remote=tcp://127.0.0.1:44301>: Stream is closed\n",
      "2024-03-27 21:09:00,169 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47758 remote=tcp://127.0.0.1:44301>: Stream is closed\n",
      "2024-03-27 21:09:00,170 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47804 remote=tcp://127.0.0.1:44301>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42783 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentialsOpening 26 granules, approx size: 2.9 GB\n",
      "\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1092.89it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1049.25it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1027.60it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1991.23it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1793.09it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1013.66it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 897.50it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 105.87it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 280339.08it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 98.87it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 350649.21it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 109.04it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 339725.56it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 106.39it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 390867.04it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 112.64it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 357547.23it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 741.15it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 112.91it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 359907.27it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 801.42it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 692.29it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 661.20it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 720.80it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1170.05it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 658.78it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 661.08it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 90.45it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 241607.37it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 423.45it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 79.30it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 303765.75it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 84.05it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 285476.19it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 90.81it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 293940.44it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 81.98it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 286225.47it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 78.13it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 247283.23it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 75.16it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 200832.24it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.00it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 293940.44it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 85.15it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 284730.82it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 43.69it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 266630.57it/s]\n",
      "2024-03-27 21:11:22,406 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:23,449 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:23,989 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:24,636 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:25,166 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:25,225 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:25,475 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:25,951 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:26,325 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:26,695 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:26,879 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:28,104 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:29,194 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:29,790 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:30,653 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:30,876 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:32,096 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:32,431 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:32,752 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:32,813 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:32,836 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:33,035 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:33,048 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:33,148 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:33,456 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:33,457 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:33,535 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:34,246 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:34,290 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:34,602 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:34,897 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:34,939 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:35,045 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:35,480 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:35,482 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:35,535 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:35,578 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:35,605 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:35,668 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:36,040 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:36,328 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:36,367 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:36,745 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:36,810 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:36,826 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:37,470 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:37,526 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:37,743 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:37,868 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:37,926 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:37,989 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:38,180 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:38,221 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:38,621 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:38,677 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:39,194 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:39,890 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:40,424 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:40,424 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:40,434 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:40,450 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:40,467 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:40,468 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:40,476 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:40,476 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:40,478 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:40,489 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:40,620 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44832 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:40,708 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:40,722 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44786 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:40,823 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44806 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:40,925 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44848 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:40,976 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:11:41,026 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44818 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:41,128 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44764 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:41,331 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44888 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:41,331 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44852 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:41,433 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44872 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:41,536 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44780 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:41,637 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44834 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:41,739 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44862 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:41,841 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44870 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:41,943 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44792 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:42,045 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44774 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "2024-03-27 21:11:42,046 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44876 remote=tcp://127.0.0.1:38991>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 43773 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 21\n",
      "Granules found: 24\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.87 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.66 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 21 granules, approx size: 2.4 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 24 granules, approx size: 2.74 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.95 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.85 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1012.31it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 947.35it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 1270.15it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1024.02it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 976.96it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 94.78it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 280339.08it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 798.66it/s]\n",
      "PROCESSING TASKS | :   0%|          | 0/25 [00:00<?, ?it/s].23it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 964.77it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 24/24 [00:00<00:00, 98.92it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 24/24 [00:00<00:00, 267011.40it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 853.62it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 774.17it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 706.21it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 98.73it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 278136.87it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 21/21 [00:00<00:00, 797.31it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 746.38it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 97.15it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 280339.08it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 700.07it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 596.07it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 94.29it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 285715.53it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 87.27it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 309806.55it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 88.46it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 284730.82it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 87.88it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 277485.76it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 86.65it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 292364.35it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 86.94it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 214872.13it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 85.71it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 279620.27it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.84it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 283251.70it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 21/21 [00:00<00:00, 63.05it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 21/21 [00:00<00:00, 253833.96it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 594.82it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 91.57it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 275383.60it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 86.41it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 281787.87it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 74.02it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 279620.27it/s]\n",
      "2024-03-27 21:13:48,610 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.72 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:13:56,043 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:01,100 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:02,592 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.74 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:02,997 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:03,898 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:03,931 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:04,233 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:04,421 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:04,785 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:05,524 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:06,142 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:08,241 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:08,749 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:09,807 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:10,143 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:10,511 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:10,901 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:11,101 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:11,234 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:11,256 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:11,272 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:11,494 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:11,876 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:12,309 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:12,570 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:12,643 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:13,002 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:13,175 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:13,345 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:13,428 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:13,810 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:13,836 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:13,922 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:13,969 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:14,038 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:14,305 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:14,370 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:14,518 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:14,703 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:14,787 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:15,622 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.18 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:16,190 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:16,241 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.92 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:16,438 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:16,442 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:16,866 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:17,833 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:18,241 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:18,843 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:19,704 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:20,417 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:21,201 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:21,259 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:22,560 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52150 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:22,743 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.90 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:14:22,762 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52222 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:22,762 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52242 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:22,863 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52214 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:22,967 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52264 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:23,068 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52166 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:23,170 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52188 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:23,271 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52232 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:23,373 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52198 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:23,473 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52192 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:23,575 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52274 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:23,676 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52260 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:23,779 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52202 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "2024-03-27 21:14:23,781 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52254 remote=tcp://127.0.0.1:37029>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42197 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 14\n",
      "Granules found: 26\n",
      "Granules found: 23\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.93 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 23 granules, approx size: 2.46 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 14 granules, approx size: 1.46 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.88 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1217.79it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1980.60it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1135.60it/s]\n",
      "PROCESSING TASKS | :   0%|          | 0/26 [00:00<?, ?it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 987.47it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 967.83it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.89it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 400926.12it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1811.64it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 102.17it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 283251.70it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 107.57it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 284730.82it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.62it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 376041.05it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 919.95it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 95.48it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 382638.26it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.99it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 349525.33it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 935.37it/s]\n",
      "PROCESSING TASKS | :   0%|          | 0/26 [00:00<?, ?it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 658.04it/s]]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 98.63it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 276781.48it/s]\n",
      "\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 816.86it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 754.70it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 93.96it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 151882.87it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 91.51it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 245612.40it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 88.96it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 364722.09it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 83.02it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 253279.23it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 82.53it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 244511.00it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 84.98it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 280339.08it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 91.22it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 383985.58it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 14/14 [00:00<00:00, 224.43it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 14/14 [00:00<00:00, 49.13it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 14/14 [00:00<00:00, 192525.43it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 23/23 [00:00<00:00, 1095.27it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 23/23 [00:00<00:00, 87.42it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 23/23 [00:00<00:00, 330373.26it/s]\n",
      "2024-03-27 21:16:35,075 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.72 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:44,762 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:45,100 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:45,174 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.82 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:45,822 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:46,069 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:47,107 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:47,944 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:48,417 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:48,752 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:49,890 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:50,765 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:51,064 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:51,234 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:51,719 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:52,365 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:53,592 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:54,040 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:54,922 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:54,997 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:55,106 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:55,175 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.82 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:55,470 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:55,695 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:55,755 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:56,206 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:56,274 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:56,343 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:56,452 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:56,543 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:56,829 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:57,168 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:57,228 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:57,277 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:57,290 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:57,894 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:58,044 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:58,598 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:58,669 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:58,853 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:58,966 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:59,077 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:59,100 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:59,104 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:59,131 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:16:59,890 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:17:00,757 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:17:00,863 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:17:01,064 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:17:01,332 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:17:01,760 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:17:02,160 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:17:02,284 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50786 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:02,463 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:17:02,487 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50832 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:02,487 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50790 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:02,588 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50764 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:02,791 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50762 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:02,893 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50746 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:02,893 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50864 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:02,996 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50806 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:03,098 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50824 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:03,300 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50738 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:03,301 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50840 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:03,504 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50852 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:03,504 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50876 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:03,605 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50772 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:03,707 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50818 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:03,709 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50886 remote=tcp://127.0.0.1:35501>: Stream is closed\n",
      "2024-03-27 21:17:03,718 - distributed.scheduler - WARNING - Received heartbeat from unregistered worker 'tcp://127.0.0.1:43553'.\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 39063 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.82 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.91 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1042.70it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1941.39it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 107.29it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 396552.38it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1869.98it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1014.71it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 102.93it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 297956.02it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1018.96it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 964.44it/s]]\n",
      "PROCESSING TASKS | :   0%|          | 0/26 [00:00<?, ?it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1530.04it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 963.68it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.02it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 295533.62it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 94.06it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 272629.76it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 977.72it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1181.19it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 99.80it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 367178.13it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 93.90it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 273999.76it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 96.70it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 320740.89it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 82.75it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 317011.35it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 90.06it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 286225.47it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 692.92it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 738.50it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 97.79it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 276080.77it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 95.00it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 277485.76it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 449.44it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 417.51it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 87.38it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 292364.35it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 93.20it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 223925.88it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 79.27it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 241051.95it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 72.20it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 283251.70it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 976.90it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 95.58it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 365945.99it/s]\n",
      "2024-03-27 21:19:27,532 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:27,815 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:27,899 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:28,963 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:29,103 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:29,257 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:30,032 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:30,243 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:30,971 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:31,146 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:32,781 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:33,524 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:33,555 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:33,650 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:33,747 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:34,360 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:36,630 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:36,873 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:37,507 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:37,518 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:37,597 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:37,833 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:38,093 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:38,205 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:38,219 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:38,279 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:38,351 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:38,388 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:38,503 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:38,780 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:38,880 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:38,931 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:39,063 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:39,153 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:39,463 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:39,573 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:39,784 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:39,848 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:40,127 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:40,338 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:41,419 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:41,420 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:41,459 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:41,514 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:41,916 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 2.99 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:41,949 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:42,070 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:42,086 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:42,088 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:42,381 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:42,450 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:42,497 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:42,955 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:43,438 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:43,556 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.16 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:43,725 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:43,825 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:43,844 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:44,361 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.15 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:44,771 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:44,798 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:44,801 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:44,813 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:44,814 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:44,825 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:44,831 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:44,837 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:44,850 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:44,855 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:19:45,172 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52748 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:45,274 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52728 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:45,376 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52740 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:45,477 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52762 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:45,579 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52724 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:45,681 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52784 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:45,783 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52810 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:45,884 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52794 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:45,986 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52800 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:46,087 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52796 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:46,290 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52814 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:46,290 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52828 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:46,392 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52856 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "2024-03-27 21:19:46,394 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:52840 remote=tcp://127.0.0.1:44975>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 38615 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.93 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1069.73it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1054.94it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 106.55it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 419430.40it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1091.81it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1280.21it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 970.37it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1777.13it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.86it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 386708.88it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1768.72it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1200.44it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1358.50it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1153.34it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 732.48it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 887.64it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 808.25it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 626.58it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 471.67it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 98.70it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 203455.04it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 99.09it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 288497.10it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 91.71it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 217234.87it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 88.37it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 294734.88it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 85.61it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 232025.33it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 87.73it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 282517.89it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 85.88it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 379971.79it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 77.75it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 383985.58it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 78.79it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 376041.05it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 75.22it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 291582.63it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 627.12it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 78.64it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 259647.39it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 70.97it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 86963.24it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 46.05it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 260267.07it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 82.71it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 260889.72it/s]\n",
      "2024-03-27 21:22:09,827 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:10,634 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:11,943 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:12,903 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:13,828 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:13,832 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:14,335 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:14,623 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:14,697 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:15,443 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:15,547 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:15,861 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:16,260 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:16,526 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:16,790 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:18,228 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:18,909 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:19,016 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.72 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:19,640 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:19,674 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:20,433 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:21,105 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:21,175 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:21,835 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:21,896 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:22,242 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:22,243 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:22,405 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:22,568 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:23,135 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:23,295 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:23,321 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:23,796 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:23,903 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:23,905 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:24,035 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:24,052 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:24,375 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:24,524 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:24,585 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:24,642 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:24,669 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:24,726 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:24,732 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:24,985 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:25,094 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:25,414 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:25,590 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:25,858 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:26,024 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:26,531 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:26,591 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.16 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:26,631 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:26,857 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:26,984 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:27,243 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:27,676 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:28,988 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:28,996 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:29,016 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:29,042 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:29,795 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:53858 remote=tcp://127.0.0.1:33597>: Stream is closed\n",
      "2024-03-27 21:22:29,896 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:53970 remote=tcp://127.0.0.1:33597>: Stream is closed\n",
      "2024-03-27 21:22:29,998 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:53898 remote=tcp://127.0.0.1:33597>: Stream is closed\n",
      "2024-03-27 21:22:30,100 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:53914 remote=tcp://127.0.0.1:33597>: Stream is closed\n",
      "2024-03-27 21:22:30,202 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54006 remote=tcp://127.0.0.1:33597>: Stream is closed\n",
      "2024-03-27 21:22:30,304 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54034 remote=tcp://127.0.0.1:33597>: Stream is closed\n",
      "2024-03-27 21:22:30,406 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:53944 remote=tcp://127.0.0.1:33597>: Stream is closed\n",
      "2024-03-27 21:22:30,507 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54014 remote=tcp://127.0.0.1:33597>: Stream is closed\n",
      "2024-03-27 21:22:30,523 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:22:30,609 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54022 remote=tcp://127.0.0.1:33597>: Stream is closed\n",
      "2024-03-27 21:22:30,610 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54004 remote=tcp://127.0.0.1:33597>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 39043 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.85 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1849.97it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1946.10it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 815.09it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 990.04it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 93.86it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 243963.99it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 106.10it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 333492.06it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.32it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 326502.71it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 908.24it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1057.54it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 106.02it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 281787.87it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 792.60it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 810.80it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1561.36it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1805.67it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 740.72it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 708.23it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1206.27it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 991.95it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 90.46it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 246166.83it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 84.29it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 364722.09it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 84.71it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 264689.09it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1443.29it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.86it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 274689.93it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 92.82it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 236555.11it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 79.57it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 242877.29it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.75it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 264689.09it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 80.62it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 295533.62it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 80.55it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 279620.27it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 77.92it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 273779.63it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 64.27it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 289262.34it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 254.93it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 89.67it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 337162.70it/s]\n",
      "2024-03-27 21:24:50,253 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:51,674 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:51,903 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:51,921 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:52,502 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:52,675 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:53,930 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:54,185 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:54,803 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:55,404 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:55,652 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:55,700 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:56,056 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:57,262 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:58,863 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:24:59,784 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:00,027 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:00,052 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:00,074 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:00,154 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:00,232 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:00,247 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:00,254 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:00,302 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:00,356 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:00,920 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:00,994 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:01,046 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:01,326 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:01,774 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:01,996 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:02,250 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:02,305 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:02,693 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.11 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:02,699 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:02,729 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:02,840 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:03,587 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:03,833 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:04,058 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:04,237 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:04,407 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:04,455 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:04,804 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:05,003 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:05,022 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:05,302 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:05,493 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:05,515 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:05,533 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:05,540 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:05,764 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:05,982 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.11 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:06,157 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:07,360 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:07,810 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:08,938 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:09,151 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:09,203 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:09,228 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:09,337 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37026 remote=tcp://127.0.0.1:39789>: Stream is closed\n",
      "2024-03-27 21:25:09,742 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37034 remote=tcp://127.0.0.1:39789>: Stream is closed\n",
      "2024-03-27 21:25:10,047 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37056 remote=tcp://127.0.0.1:39789>: Stream is closed\n",
      "2024-03-27 21:25:10,249 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37006 remote=tcp://127.0.0.1:39789>: Stream is closed\n",
      "2024-03-27 21:25:10,249 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:36984 remote=tcp://127.0.0.1:39789>: Stream is closed\n",
      "2024-03-27 21:25:10,351 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37042 remote=tcp://127.0.0.1:39789>: Stream is closed\n",
      "2024-03-27 21:25:10,352 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:25:10,452 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:36946 remote=tcp://127.0.0.1:39789>: Stream is closed\n",
      "2024-03-27 21:25:10,554 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:36974 remote=tcp://127.0.0.1:39789>: Stream is closed\n",
      "2024-03-27 21:25:10,656 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37070 remote=tcp://127.0.0.1:39789>: Stream is closed\n",
      "2024-03-27 21:25:10,758 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:36960 remote=tcp://127.0.0.1:39789>: Stream is closed\n",
      "2024-03-27 21:25:10,758 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:37012 remote=tcp://127.0.0.1:39789>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 44905 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 0\n",
      "Granules found: 10\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 21\n",
      "Granules found: 12\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 10\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 20\n",
      "Opening 26 granules, approx size: 2.96 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.93 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 10 granules, approx size: 1.1 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.76 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.9 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 21 granules, approx size: 2.24 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 12 granules, approx size: 1.22 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.87 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 10 granules, approx size: 1.14 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 20 granules, approx size: 2.25 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.88 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.96 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1897.97it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1391.62it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 989.02it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1163.87it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 989.69it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1691.93it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.52it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 374748.81it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 107.30it/s]\n",
      "\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 267940.80it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 12/12 [00:00<00:00, 672.66it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 21/21 [00:00<00:00, 748.28it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 105.86it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 273313.04it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 105.44it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 304614.26it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 107.92it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 286978.69it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1214.94it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 109.04it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 291582.63it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1151.50it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 10/10 [00:00<00:00, 545.72it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 10/10 [00:00<00:00, 299.42it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 12/12 [00:00<00:00, 46.15it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 12/12 [00:00<00:00, 176602.27it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 21/21 [00:00<00:00, 77.05it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 21/21 [00:00<00:00, 242645.69it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 90.02it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 177898.70it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 20/20 [00:00<00:00, 661.13it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.15it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 223925.88it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 390.48it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 82.99it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 257805.92it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 10/10 [00:00<00:00, 34.63it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 10/10 [00:00<00:00, 151418.92it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 10/10 [00:00<00:00, 38.66it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 10/10 [00:00<00:00, 205603.14it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 91.63it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 281061.61it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 20/20 [00:00<00:00, 57.19it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 20/20 [00:00<00:00, 241051.95it/s]\n",
      "2024-03-27 21:27:07,288 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.74 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:23,007 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:23,193 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:25,242 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:25,788 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:26,626 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:27,152 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:27,233 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:28,380 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:29,655 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:30,286 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:30,306 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:31,486 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:31,575 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:32,142 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:32,866 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:32,894 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:33,107 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:33,293 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:33,392 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.11 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:33,418 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:34,147 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:35,281 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:35,577 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:35,887 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:36,549 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:36,553 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:36,725 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:36,982 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:37,186 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:37,233 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:38,479 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:39,035 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:39,426 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:39,850 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:41,153 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:41,178 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:41,180 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:41,186 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:41,186 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:41,192 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:41,207 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:41,226 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:41,232 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:41,352 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:60596 remote=tcp://127.0.0.1:45223>: Stream is closed\n",
      "2024-03-27 21:27:41,453 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:60634 remote=tcp://127.0.0.1:45223>: Stream is closed\n",
      "2024-03-27 21:27:41,552 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:27:41,961 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:60606 remote=tcp://127.0.0.1:45223>: Stream is closed\n",
      "2024-03-27 21:27:42,163 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:60622 remote=tcp://127.0.0.1:45223>: Stream is closed\n",
      "2024-03-27 21:27:42,266 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:60502 remote=tcp://127.0.0.1:45223>: Stream is closed\n",
      "2024-03-27 21:27:42,367 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:60564 remote=tcp://127.0.0.1:45223>: Stream is closed\n",
      "2024-03-27 21:27:42,569 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:60562 remote=tcp://127.0.0.1:45223>: Stream is closed\n",
      "2024-03-27 21:27:42,570 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:60580 remote=tcp://127.0.0.1:45223>: Stream is closed\n",
      "2024-03-27 21:27:42,671 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:60632 remote=tcp://127.0.0.1:45223>: Stream is closed\n",
      "2024-03-27 21:27:42,772 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:60574 remote=tcp://127.0.0.1:45223>: Stream is closed\n",
      "2024-03-27 21:27:42,774 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:60638 remote=tcp://127.0.0.1:45223>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 36389 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.63 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.84 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 25\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.96 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.89 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.93 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.88 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.95 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.91 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.39 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.92 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.75 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.85 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1227.26it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1668.69it/s]\n",
      "PROCESSING TASKS | :   0%|          | 0/26 [00:00<?, ?it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1008.92it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1165.32it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 1856.05it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.87it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 357547.23it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 935.65it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 103.78it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 382638.26it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.99it/s]\n",
      "\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 286978.69it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 102.85it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 297144.15it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1466.66it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 104.77it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 284730.82it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 884.75it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 864.32it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1192.10it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 3409.15it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 89.44it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 284166.94it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 683.34it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 809.10it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 91.72it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 283251.70it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 78.30it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 251851.97it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 84.60it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 206929.61it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 76.75it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 276080.77it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 89.52it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 281061.61it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 91.12it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 298772.34it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 75.88it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 293940.44it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 84.63it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 274689.93it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 87.16it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 264689.09it/s]\n",
      "2024-03-27 21:29:51,794 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:29:55,437 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:29:59,943 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:00,536 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:00,865 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:00,919 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:01,956 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:02,875 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:03,194 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:03,288 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:03,741 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:04,405 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:05,010 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:05,668 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:05,676 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:05,881 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:06,249 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:07,617 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:08,265 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:08,335 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:08,888 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:09,312 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:09,517 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:09,665 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:09,735 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:09,812 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:10,136 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:10,264 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:10,636 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.21 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:10,836 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:10,866 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:10,885 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:11,046 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:11,246 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:11,667 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:11,689 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:11,993 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:12,305 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:12,620 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:13,069 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:13,285 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:13,289 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.21 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:13,455 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:13,478 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:13,748 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.17 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:14,042 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:14,050 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:15,110 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.22 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:15,739 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:15,766 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:15,981 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:16,316 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:16,434 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:16,695 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:19,834 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:20,299 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:20,636 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:20,964 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:21,119 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:21,994 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:23,076 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:23,285 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:23,389 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:23,749 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:25,111 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:25,767 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:25,838 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:26,083 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:26,316 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:29,934 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:30,299 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:30,636 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:30,964 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:31,220 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:32,093 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:33,076 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:33,384 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:33,488 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:33,849 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:35,209 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:35,838 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:35,866 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:36,180 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:36,316 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:39,934 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:40,300 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:40,735 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:40,964 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:41,319 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:42,093 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:43,175 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:43,384 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:43,488 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:43,948 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:45,211 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:45,936 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:45,966 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:46,182 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:46,318 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:50,033 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:50,400 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:50,835 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:50,965 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:51,319 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:52,094 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:53,175 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:53,384 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:53,489 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:53,948 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:55,211 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:55,937 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:55,966 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:56,281 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:30:56,417 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:00,034 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:00,499 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:00,836 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:01,064 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:01,420 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:02,194 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:03,275 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:03,483 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:03,489 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:03,949 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:05,310 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:05,966 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:06,038 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:06,380 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:06,516 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:10,134 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:10,599 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:10,934 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:11,065 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:11,519 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:12,294 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:13,374 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:13,484 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:13,588 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:14,048 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:15,310 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:16,066 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:16,137 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:16,382 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:16,516 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:20,135 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:20,599 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:20,935 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:21,065 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:21,520 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:22,295 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:23,475 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:23,583 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:23,589 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:24,048 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:25,310 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:26,066 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:26,138 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:26,482 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:26,518 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:30,136 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:30,600 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:30,935 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:31,166 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:31,521 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:32,296 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:33,475 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:33,584 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:33,688 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:34,050 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:35,310 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:36,167 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:36,238 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:36,582 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:36,617 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:40,234 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:40,699 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:41,035 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:41,265 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:41,619 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:42,394 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:43,576 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:43,684 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:43,689 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:44,150 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:45,409 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:46,168 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:46,238 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:46,582 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:46,716 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:50,235 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:50,700 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:51,036 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:51,365 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:51,620 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:52,394 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:53,675 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:53,689 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:53,784 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:54,150 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:55,409 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:56,239 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:56,266 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:56,681 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:31:56,718 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:00,334 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:00,700 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:01,137 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:01,466 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:01,620 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:02,394 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:03,675 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:03,788 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:03,884 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:04,150 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:05,410 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:06,267 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:06,338 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:06,682 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:06,817 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:10,434 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:10,799 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:11,137 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:11,565 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:11,719 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:12,494 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:13,775 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:13,789 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:13,984 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:14,249 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:15,509 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:16,367 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:16,437 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:16,781 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:16,817 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:20,434 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:20,800 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:21,235 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:21,666 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:21,720 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:22,594 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:23,875 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:23,888 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:24,084 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:24,249 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:25,509 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:26,437 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:26,466 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:26,781 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:26,916 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:30,533 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:30,900 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:31,236 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:31,766 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:31,819 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:32,694 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:33,888 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:33,974 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:34,084 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:34,249 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:35,509 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:36,438 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:36,567 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:36,881 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:37,016 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:40,635 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:40,999 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:41,335 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:41,865 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:41,919 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:42,795 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:43,974 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:43,988 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:44,184 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:44,348 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:45,510 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:46,537 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:46,667 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:46,980 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:47,016 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:50,635 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:51,099 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:51,336 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:51,920 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:51,966 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:52,894 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:53,975 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:53,989 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:54,185 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:54,348 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:55,609 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:56,638 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:56,667 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:57,016 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:32:57,082 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:00,734 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:01,201 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:01,435 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:02,018 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:02,064 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:02,994 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:03,975 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:04,088 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:04,285 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:04,349 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:05,610 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:06,738 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:06,766 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:07,083 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:07,116 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:10,835 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:11,300 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:11,435 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:12,021 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:12,064 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:12,994 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:14,074 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:14,088 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:14,384 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:14,448 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:15,710 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:16,738 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:16,767 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:17,119 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:17,181 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:20,934 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:21,400 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:21,536 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:22,065 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:22,118 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:22,994 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:24,076 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:24,089 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:24,384 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:24,449 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:25,710 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:26,837 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:26,867 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:27,217 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:27,282 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:31,033 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:31,499 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:31,536 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:32,065 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:32,120 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:33,094 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:34,174 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:34,187 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:34,484 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:34,548 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:35,711 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:36,837 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:36,966 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:37,317 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:37,381 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:37,993 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 398.80 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:39,033 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 402.84 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:41,499 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:41,636 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:42,120 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:42,164 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:42,199 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 401.21 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:44,175 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:44,190 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:44,484 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:44,548 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:45,810 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:46,837 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:47,065 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:47,317 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:47,381 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:51,734 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:52,120 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:52,166 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:54,275 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:54,287 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:54,484 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:54,549 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:55,809 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 401.30 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:56,838 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:57,067 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:57,416 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:33:57,482 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:01,736 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:01,966 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 404.01 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:02,167 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:02,220 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:04,275 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:04,319 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 400.46 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:04,389 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:04,583 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:04,649 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:06,537 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 400.44 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:07,417 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:07,581 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:09,684 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 400.75 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:11,834 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:12,265 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:12,680 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 399.08 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:14,374 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:14,488 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:14,650 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:15,574 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 399.91 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:17,517 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:17,735 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 400.36 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:17,788 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 399.54 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:19,948 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 402.39 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:22,365 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:27,618 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:28,817 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 401.88 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:32,465 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:42,564 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:34:52,564 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:35:02,565 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:35:12,666 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:35:22,765 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:35:32,864 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:35:42,865 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:35:52,865 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:36:02,964 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:36:13,065 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:36:23,164 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:36:33,164 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:36:43,166 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:36:53,166 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:37:03,265 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:37:13,364 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:37:23,365 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:37:33,464 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:37:43,464 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:37:43,711 - distributed.scheduler - WARNING - Worker failed to heartbeat within 300 seconds. Closing: <WorkerState 'tcp://127.0.0.1:42735', name: 10, status: running, memory: 0, processing: 1>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.95 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 2121.01it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 106.73it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 392273.04it/s]\n",
      "2024-03-27 21:37:53,465 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:38:02,022 - distributed.nanny - WARNING - Worker process still alive after 3.1999995422363288 seconds, killing\n",
      "2024-03-27 21:38:03,564 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:38:13,565 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:38:23,665 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:38:33,765 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:38:43,765 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:38:53,865 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:39:03,964 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:39:14,065 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:39:24,166 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:39:34,166 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:39:44,192 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.72 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:39:44,263 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:39:48,562 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:39:48,944 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:39:48,992 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:39:53,176 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47428 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "2024-03-27 21:39:53,277 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47490 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "2024-03-27 21:39:53,378 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47402 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "2024-03-27 21:39:53,480 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47460 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "2024-03-27 21:39:53,683 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47408 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "2024-03-27 21:39:53,784 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47442 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "2024-03-27 21:39:53,785 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47454 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "2024-03-27 21:39:53,886 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47520 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "2024-03-27 21:39:54,089 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47392 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "2024-03-27 21:39:54,089 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47476 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "2024-03-27 21:39:54,190 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47504 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "2024-03-27 21:39:54,292 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47502 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "2024-03-27 21:39:54,292 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47492 remote=tcp://127.0.0.1:43953>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 39267 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 12\n",
      "Granules found: 6\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 6 granules, approx size: 0.68 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 12 granules, approx size: 1.38 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.96 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.86 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.74 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 1.11 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.29 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.83 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 12/12 [00:00<00:00, 493.52it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 12/12 [00:00<00:00, 59.13it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 12/12 [00:00<00:00, 247939.15it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 2447.80it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1146.19it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 102.77it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 289262.34it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 106.50it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 397999.65it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 953.51it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 105.61it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 361577.93it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 980.56it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 105.20it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 395115.59it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1110.26it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 1084.86it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.04it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 378652.44it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 107.54it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 412825.20it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1027.53it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 829.87it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 981.42it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 99.35it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 291582.63it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1529.20it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 984.49it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 88.99it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 384093.77it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.94it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 308928.91it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 94.85it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 307188.46it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 105.74it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 214247.36it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1121.38it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 6/6 [00:00<00:00, 324.47it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 1213.56it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.58it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 329461.95it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 6/6 [00:00<00:00, 21.43it/s]]\n",
      "COLLECTING RESULTS | : 100%|██████████| 6/6 [00:00<00:00, 129055.51it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 91.01it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 374491.43it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 871.30it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 93.58it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 248976.95it/s]\n",
      "2024-03-27 21:41:22,858 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.72 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:41:29,096 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:41:29,258 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:41:32,858 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.01 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:41:42,957 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.01 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:41:52,958 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.01 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:01,221 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:02,958 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.01 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:08,888 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:11,319 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:13,059 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.01 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:16,940 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:18,245 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:19,290 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:19,665 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:19,961 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:20,097 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:20,485 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:20,801 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:21,144 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:21,320 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:21,484 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:21,658 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:23,157 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.01 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:23,200 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:23,642 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:24,109 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:24,882 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:26,541 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:26,782 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:27,040 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:27,647 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:27,737 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:27,772 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:27,999 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:28,133 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:28,251 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:28,452 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:28,629 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:28,978 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:29,100 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:29,110 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:29,290 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:29,336 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:29,349 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:29,442 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:29,642 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:29,671 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:29,972 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:30,187 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:30,320 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:30,583 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:30,899 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:31,242 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:31,420 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:31,484 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:31,758 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:33,158 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.01 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:36,383 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:37,139 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:37,772 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:37,790 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:37,796 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:38,351 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:42:38,527 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:55546 remote=tcp://127.0.0.1:38297>: Stream is closed\n",
      "2024-03-27 21:42:38,730 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:55554 remote=tcp://127.0.0.1:38297>: Stream is closed\n",
      "2024-03-27 21:42:38,832 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:55602 remote=tcp://127.0.0.1:38297>: Stream is closed\n",
      "2024-03-27 21:42:38,933 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:55692 remote=tcp://127.0.0.1:38297>: Stream is closed\n",
      "2024-03-27 21:42:39,035 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:55614 remote=tcp://127.0.0.1:38297>: Stream is closed\n",
      "2024-03-27 21:42:39,136 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:55650 remote=tcp://127.0.0.1:38297>: Stream is closed\n",
      "2024-03-27 21:42:39,339 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:55632 remote=tcp://127.0.0.1:38297>: Stream is closed\n",
      "2024-03-27 21:42:39,339 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:55688 remote=tcp://127.0.0.1:38297>: Stream is closed\n",
      "2024-03-27 21:42:39,340 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:55674 remote=tcp://127.0.0.1:38297>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 46085 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 15\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 0\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 18\n",
      "Granules found: 26\n",
      "Granules found: 4\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 15 granules, approx size: 1.73 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 3\n",
      "Granules found: 26\n",
      "Granules found: 6\n",
      "Opening 26 granules, approx size: 2.91 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 18 granules, approx size: 2.07 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 6 granules, approx size: 0.69 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 4 granules, approx size: 0.02 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 3 granules, approx size: 0.25 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1576.49it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1016.87it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1010.51it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1207.85it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 102.88it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 274689.93it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 94.84it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 325528.07it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 718.39it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 946.92it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1292.45it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 118.56it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 392273.04it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 18/18 [00:00<00:00, 591.44it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 111.70it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 318865.22it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 6/6 [00:00<00:00, 199.95it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 3/3 [00:00<00:00, 225.25it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 15/15 [00:00<00:00, 507.20it/s]\n",
      "PROCESSING TASKS | :   4%|▍         | 1/26 [00:00<00:05,  4.75it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 950.34it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 98.50it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 298772.34it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.39it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 284730.82it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 97.02it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 267940.80it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 18/18 [00:00<00:00, 71.96it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 18/18 [00:00<00:00, 230175.22it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 3/3 [00:00<00:00, 16.31it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 3/3 [00:00<00:00, 65536.00it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 6/6 [00:00<00:00, 25.64it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 6/6 [00:00<00:00, 105296.33it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 739.19it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 4/4 [00:00<00:00, 16.98it/s]s]\n",
      "\n",
      "COLLECTING RESULTS | : 100%|██████████| 4/4 [00:00<00:00, 76608.29it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 15/15 [00:00<00:00, 217697.44it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 94.20it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 276781.48it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 879.49it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 84.85it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 289262.34it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 72.22it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 279620.27it/s]\n",
      "2024-03-27 21:44:55,719 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:44:55,996 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:44:56,444 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:44:56,561 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:44:57,101 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:44:57,986 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:44:58,311 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:44:58,921 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:44:59,239 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:00,138 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:01,714 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:02,100 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:02,121 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:02,161 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:02,256 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:02,688 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:03,210 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:03,329 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:03,446 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:04,163 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:05,398 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:05,523 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:05,719 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:05,918 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:06,008 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:06,171 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:06,353 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:06,508 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:06,543 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:06,660 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:07,201 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:07,843 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:07,861 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:07,909 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:08,086 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:08,312 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:45:08,642 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33580 remote=tcp://127.0.0.1:34817>: Stream is closed\n",
      "2024-03-27 21:45:08,844 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33524 remote=tcp://127.0.0.1:34817>: Stream is closed\n",
      "2024-03-27 21:45:09,048 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33570 remote=tcp://127.0.0.1:34817>: Stream is closed\n",
      "2024-03-27 21:45:09,048 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33476 remote=tcp://127.0.0.1:34817>: Stream is closed\n",
      "2024-03-27 21:45:09,150 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33498 remote=tcp://127.0.0.1:34817>: Stream is closed\n",
      "2024-03-27 21:45:09,251 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33550 remote=tcp://127.0.0.1:34817>: Stream is closed\n",
      "2024-03-27 21:45:09,354 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33598 remote=tcp://127.0.0.1:34817>: Stream is closed\n",
      "2024-03-27 21:45:09,455 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33588 remote=tcp://127.0.0.1:34817>: Stream is closed\n",
      "2024-03-27 21:45:09,457 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33596 remote=tcp://127.0.0.1:34817>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 39987 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 25 granules, approx size: 2.87 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.87 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1114.29it/s]\n",
      "QUEUEING TASKS | :   0%|          | 0/26 [00:00<?, ?it/s]084.60it/s]\n",
      "QUEUEING TASKS | :   0%|          | 0/25 [00:00<?, ?it/s]915.75it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 1838.67it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 958.48it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1556.68it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 94.88it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 365945.99it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 98.99it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 293940.44it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 94.72it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 285476.19it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 96.60it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 312076.19it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 862.98it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 107.72it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 284939.13it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1403.64it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 98.41it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 331464.75it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1450.97it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 99.53it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 352918.78it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 822.46it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 89.77it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 320740.89it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 92.32it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 285476.19it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 88.56it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 277485.76it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 719.59it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 678.61it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 996.39it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 599.75it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 823.48it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 611.62it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 97.46it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 285476.19it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 87.72it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 308056.23it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 68.35it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 275383.60it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 75.20it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 286225.47it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 74.26it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 316092.48it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 77.22it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 297144.15it/s]\n",
      "2024-03-27 21:47:28,630 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:29,371 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:29,850 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:29,887 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:30,976 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:32,263 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:32,291 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:33,805 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:33,848 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:34,285 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:34,526 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:34,813 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:34,899 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:35,104 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:38,236 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:38,249 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:38,465 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:38,716 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:39,121 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:39,201 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:39,306 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:39,682 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:39,684 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:39,917 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:39,935 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:40,016 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:40,437 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:40,976 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:40,988 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:41,239 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:41,865 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:42,278 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:42,291 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:42,520 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:42,535 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:42,548 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:42,620 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:42,873 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:42,995 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:43,219 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:43,432 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:43,483 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:43,960 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:44,126 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:44,154 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:44,162 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:44,184 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:44,480 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:44,928 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:44,980 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:45,040 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:45,202 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.19 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:45,487 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:45,515 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,270 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,278 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,281 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,285 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,285 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,290 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,303 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,304 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,314 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,325 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,329 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,346 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,348 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,349 - distributed.worker.memory - WARNING - Worker is at 78% memory usage. Resuming worker. Process memory: 3.00 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:47:47,874 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44734 remote=tcp://127.0.0.1:42651>: Stream is closed\n",
      "2024-03-27 21:47:47,976 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44774 remote=tcp://127.0.0.1:42651>: Stream is closed\n",
      "2024-03-27 21:47:48,078 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44708 remote=tcp://127.0.0.1:42651>: Stream is closed\n",
      "2024-03-27 21:47:48,179 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44738 remote=tcp://127.0.0.1:42651>: Stream is closed\n",
      "2024-03-27 21:47:48,281 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44800 remote=tcp://127.0.0.1:42651>: Stream is closed\n",
      "2024-03-27 21:47:48,382 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44722 remote=tcp://127.0.0.1:42651>: Stream is closed\n",
      "2024-03-27 21:47:48,484 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44794 remote=tcp://127.0.0.1:42651>: Stream is closed\n",
      "2024-03-27 21:47:48,585 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44796 remote=tcp://127.0.0.1:42651>: Stream is closed\n",
      "2024-03-27 21:47:48,687 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44808 remote=tcp://127.0.0.1:42651>: Stream is closed\n",
      "2024-03-27 21:47:48,889 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44784 remote=tcp://127.0.0.1:42651>: Stream is closed\n",
      "2024-03-27 21:47:48,889 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44786 remote=tcp://127.0.0.1:42651>: Stream is closed\n",
      "2024-03-27 21:47:48,891 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44762 remote=tcp://127.0.0.1:42651>: Stream is closed\n",
      "/opt/coiled/env/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 35723 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Granules found: 25\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.97 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.99 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 25 granules, approx size: 2.87 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1960.91it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1070.95it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1046.75it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 965.29it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 933.57it/s]]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1842.22it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 66.08it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 338670.51it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 935.40it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 939.54it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 71.61it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 269263.96it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 68.87it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 373465.42it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.44it/s] \n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 314270.62it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1017.17it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1445.26it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1409.90it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 962.16it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1057.90it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 105.29it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 347299.06it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 102.11it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 281061.61it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 87.62it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 255390.88it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.95it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 288497.10it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 90.00it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 286225.47it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 78.66it/s]\n",
      "QUEUEING TASKS | :   0%|          | 0/26 [00:00<?, ?it/s] 78.79it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 286225.47it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 245612.40it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 79.06it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 280339.08it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 83.93it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 288497.10it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 776.41it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 84.42it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 225313.85it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 569.59it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 75.69it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 237772.34it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 1078.49it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 114.04it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 326502.71it/s]\n",
      "2024-03-27 21:50:06,734 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:07,385 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:08,819 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:10,071 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:10,127 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:10,298 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:10,545 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:10,732 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:12,030 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:12,361 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:12,624 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.71 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:12,740 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:12,928 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:14,783 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:15,354 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:15,504 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:15,608 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:16,883 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:17,305 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:17,772 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:18,053 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:18,148 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:18,176 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:18,497 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:18,872 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:19,080 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:19,169 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.03 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:19,233 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:19,240 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:19,400 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:20,010 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:20,169 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:20,503 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:20,702 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:20,707 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:20,796 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:20,816 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:21,009 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:21,102 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:21,246 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:21,327 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:21,359 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:21,423 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:22,063 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:22,064 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:22,185 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:22,397 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.18 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:22,701 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.09 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:22,796 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.11 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:22,918 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.07 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:23,115 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.10 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:23,546 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:23,948 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.04 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:24,002 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:24,157 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:24,602 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:24,888 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:25,038 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:25,505 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.17 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:25,769 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:26,979 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:28,083 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:29,318 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:30,170 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:30,527 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:30,739 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:30,798 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:31,334 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:32,129 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:32,496 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:32,723 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:32,837 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:33,127 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:34,953 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:35,604 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:35,804 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:37,078 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:38,183 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:39,319 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:40,171 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:40,527 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:40,740 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:40,799 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:41,433 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:42,228 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:42,596 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:42,822 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:42,838 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:43,128 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:44,953 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:45,604 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:45,804 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:47,178 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:48,183 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:49,418 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:50,171 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:50,527 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:50,799 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:50,841 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:51,532 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:52,228 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:52,695 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:52,823 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:52,838 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:53,227 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:55,052 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:55,604 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:55,902 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:57,179 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:58,283 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:50:59,517 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:00,273 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:00,527 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:00,898 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:00,939 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:01,533 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:02,329 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:02,695 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:02,838 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:02,924 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:03,328 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:05,053 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:05,704 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:05,903 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:07,280 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:08,385 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:09,520 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:10,273 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:10,626 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:10,900 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:10,940 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:11,633 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:12,429 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:12,696 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:12,937 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:13,023 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:13,426 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:15,152 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:15,804 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:15,904 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:17,379 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:18,484 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:19,619 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:20,372 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:20,727 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:20,940 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:21,000 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:21,732 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:22,430 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:22,697 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:22,938 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:23,023 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:23,428 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:25,253 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:25,903 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:26,004 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:27,478 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:28,583 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:29,619 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:30,471 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:30,826 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:30,941 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:31,098 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:31,834 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:32,527 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:32,797 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:33,037 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:33,123 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:33,429 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:35,352 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:35,905 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:36,103 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:37,478 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:38,584 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:39,619 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:40,472 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:40,928 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:41,040 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:41,099 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:41,834 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:42,529 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:42,797 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:43,037 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:43,124 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:43,429 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:45,354 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:46,003 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:46,202 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:47,579 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:48,584 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:49,718 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:50,472 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:51,027 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:51,040 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:51,099 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:51,932 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:52,628 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:52,895 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:53,037 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:53,224 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:53,528 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:55,452 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:56,004 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:56,203 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:57,679 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:58,682 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:51:59,818 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:00,570 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:01,040 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:01,126 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:01,199 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:01,933 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:02,727 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:02,896 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:03,136 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:03,322 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:03,627 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:05,552 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:06,103 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:06,303 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:07,778 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:08,683 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:09,818 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:10,571 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:11,126 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:11,141 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:11,299 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:11,933 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:12,729 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:12,996 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:13,137 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:13,322 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:13,627 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:15,552 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:16,205 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:16,304 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:17,779 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:18,782 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:19,818 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:20,672 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:21,127 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:21,240 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:21,399 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:22,032 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:22,828 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:23,096 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:23,137 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:23,323 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:23,628 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:25,552 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:26,304 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:26,306 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:27,780 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:28,784 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:29,919 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:30,672 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:31,226 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:31,342 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:31,400 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:32,132 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:32,829 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:33,195 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:33,236 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:33,324 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:33,728 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:35,651 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:36,403 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:36,405 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:37,879 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:38,883 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:40,019 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:40,772 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:41,226 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:41,342 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:41,501 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:42,132 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:42,929 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:43,196 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:43,238 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:43,423 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:43,827 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:45,652 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:46,502 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:46,503 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:47,978 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:48,884 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:50,118 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:50,871 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:51,325 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:51,342 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:51,599 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:52,133 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:53,027 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:53,296 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:53,339 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:53,522 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:53,926 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:55,753 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:56,503 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:56,504 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:58,078 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:52:58,984 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:00,118 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:00,872 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:01,327 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:01,440 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:01,600 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:02,231 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:03,129 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:03,297 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:03,339 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:03,523 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:03,929 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:05,753 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:06,603 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:06,603 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:08,179 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:08,984 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:10,217 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:10,972 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:11,427 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:11,441 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:11,698 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:12,231 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:13,228 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:13,396 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:13,438 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:13,622 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:14,027 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:15,853 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:16,604 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:16,702 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:18,277 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:19,083 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:20,219 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:21,070 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:21,441 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:21,527 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:21,699 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:22,232 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:23,327 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:23,396 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:23,537 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:23,622 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:24,127 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:25,953 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:26,702 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:26,703 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:28,280 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:29,083 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:30,318 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:31,071 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:31,540 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:31,626 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:31,699 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:32,233 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:33,430 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:33,495 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:33,623 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:33,636 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:34,128 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:36,052 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:36,804 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:36,805 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:38,379 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:39,084 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:40,319 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:41,170 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:41,641 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:41,725 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:41,799 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:42,331 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:43,496 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:43,529 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:43,624 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:43,637 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:44,227 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:46,151 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:46,804 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:46,805 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:48,379 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:49,183 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:50,418 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:51,171 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:51,727 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:51,740 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:51,799 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:52,333 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:53,596 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:53,629 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:53,723 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:53,736 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:54,227 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:56,152 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:56,902 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:56,905 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:58,478 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:53:59,183 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:00,419 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:01,172 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:01,741 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:01,827 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:01,898 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:02,334 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:03,696 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:03,727 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:03,737 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:03,822 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:04,328 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:06,251 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:06,903 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:07,005 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:07,602 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 403.40 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:07,726 - distributed.worker.memory - WARNING - Worker is at 13% memory usage. Resuming worker. Process memory: 526.79 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:08,479 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 21:54:09,283 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:10,519 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:11,273 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:11,841 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:11,900 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:12,433 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.14 GiB -- Worker memory limit: 3.80 GiB\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 3002.53it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 111.05it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 397999.65it/s]\n",
      "2024-03-27 21:54:13,696 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:13,728 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:13,822 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:13,838 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:14,429 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:14,971 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 400.56 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:16,252 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:17,104 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:18,478 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 401.03 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:19,283 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:20,618 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:21,083 - distributed.worker.memory - WARNING - Worker is at 13% memory usage. Resuming worker. Process memory: 528.25 MiB -- Worker memory limit: 3.80 GiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 21:54:21,941 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:22,000 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:22,132 - distributed.worker.memory - WARNING - Worker is at 13% memory usage. Resuming worker. Process memory: 525.49 MiB -- Worker memory limit: 3.80 GiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening 26 granules, approx size: 2.95 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n",
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 21:54:23,728 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:23,797 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.24 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:23,924 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:23,936 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:24,236 - distributed.worker.memory - WARNING - Worker is at 13% memory usage. Resuming worker. Process memory: 527.23 MiB -- Worker memory limit: 3.80 GiB\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 2780.73it/s]\n",
      "PROCESSING TASKS | :   0%|          | 0/26 [00:00<?, ?it/s]2024-03-27 21:54:24,528 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 106.14it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 399457.52it/s]\n",
      "2024-03-27 21:54:24,895 - distributed.worker.memory - WARNING - Worker is at 13% memory usage. Resuming worker. Process memory: 525.70 MiB -- Worker memory limit: 3.80 GiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 21:54:25,327 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 401.77 MiB -- Worker memory limit: 3.80 GiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Opening 25 granules, approx size: 2.87 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 15383.26it/s]\n",
      "PROCESSING TASKS | :   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 100.28it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 357547.23it/s]\n",
      "2024-03-27 21:54:26,352 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:26,903 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 403.11 MiB -- Worker memory limit: 3.80 GiB\n",
      "QUEUEING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 1638.96it/s]\n",
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 2650.24it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 25/25 [00:00<00:00, 103.10it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 25/25 [00:00<00:00, 309314.45it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 101.44it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 367178.13it/s]\n",
      "2024-03-27 21:54:30,717 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:31,229 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 400.78 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:32,000 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:32,040 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:34,023 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.13 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:36,354 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:37,140 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 400.39 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:38,152 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 401.04 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:40,622 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 403.85 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:40,719 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.12 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:42,098 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.25 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:43,119 - distributed.worker.memory - WARNING - Worker is at 10% memory usage. Resuming worker. Process memory: 402.59 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:54:43,299 - distributed.worker.memory - WARNING - Worker is at 13% memory usage. Resuming worker. Process memory: 529.58 MiB -- Worker memory limit: 3.80 GiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 26\n",
      "Opening 26 granules, approx size: 2.98 GB\n",
      "using endpoint: https://archive.podaac.earthdata.nasa.gov/s3credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QUEUEING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 2930.79it/s]\n",
      "PROCESSING TASKS | : 100%|██████████| 26/26 [00:00<00:00, 89.93it/s]\n",
      "COLLECTING RESULTS | : 100%|██████████| 26/26 [00:00<00:00, 276781.48it/s]\n",
      "2024-03-27 21:56:00,626 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.68 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:06,226 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:10,627 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.28 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:15,284 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:17,433 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.66 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:17,836 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.69 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:18,727 - distributed.worker.memory - WARNING - Worker is at 14% memory usage. Resuming worker. Process memory: 557.45 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:20,944 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:23,096 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.67 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:23,160 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:23,372 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.05 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:25,384 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.28 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:27,533 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.27 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:27,838 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.18 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:28,695 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.08 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:33,196 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.27 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:35,385 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.28 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:37,633 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.27 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:37,937 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.18 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:38,496 - distributed.worker.memory - WARNING - Worker is at 14% memory usage. Resuming worker. Process memory: 555.45 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:41,298 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 2.70 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:41,437 - distributed.worker.memory - WARNING - Worker is at 14% memory usage. Resuming worker. Process memory: 559.61 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:42,284 - distributed.worker.memory - WARNING - Worker is at 14% memory usage. Resuming worker. Process memory: 558.68 MiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:45,998 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:46,378 - distributed.worker.memory - WARNING - Worker is at 79% memory usage. Resuming worker. Process memory: 3.02 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:46,398 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 3.06 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:47,633 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.27 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:50,423 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46342 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:50,523 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46380 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:50,625 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46368 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:50,727 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46356 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:50,930 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46398 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:50,930 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54332 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:51,132 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46382 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:51,133 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54296 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:51,300 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.28 GiB -- Worker memory limit: 3.80 GiB\n",
      "2024-03-27 21:56:51,335 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46386 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:51,336 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46378 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:51,538 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54340 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:51,538 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54316 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:51,740 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54338 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:51,741 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46404 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:51,842 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54350 remote=tcp://127.0.0.1:37263>: Stream is closed\n",
      "2024-03-27 21:56:51,844 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/worker.py\", line 1255, in heartbeat\n",
      "    response = await retry_operation(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1396, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/core.py\", line 1155, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 237, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/coiled/env/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54304 remote=tcp://127.0.0.1:37263>: Stream is closed\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "plot_1day_delayed = delayed(plot_1day)\n",
    "\n",
    "for i in range(1, len(i_list)):\n",
    "\n",
    "    # Starts cluster:\n",
    "    client = Client(n_workers=16, threads_per_worker=1)\n",
    "    client.run(auth_env, auth=earthaccess.auth_environ())\n",
    "\n",
    "    # Runs batch of tasks:\n",
    "    tasks_i = [\n",
    "        plot_1day_delayed(d, outputdir=\"./animation_images/\", ancillary_images=ancillary_images) \n",
    "        for d in dates_2022[i_list[i-1] : i_list[i]] \n",
    "        ]\n",
    "    results_i = da.compute(*tasks_i)\n",
    "\n",
    "    # Closes cluster:\n",
    "    client.close()\n",
    "\n",
    "    results.append(results_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac63e013-44d5-4c61-bfef-2ff6590e47cd",
   "metadata": {},
   "source": [
    "### In Development: Parallel computing with Coiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66136806-84af-4656-a7a7-4f1f207fdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffce645-d717-4ae5-a647-a23a086cdd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1day_coiled = coiled.function(\n",
    "    region=\"us-west-2\", spot_policy=\"on-demand\", \n",
    "    vm_type = \"m6i.large\",\n",
    "    #vm_type = \"c7g.medium\",\n",
    "    environ=earthaccess.auth_environ()\n",
    "    )(plot_1day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463bbed-b85f-4db6-856a-4113e599d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spin up cluster and scales workers:\n",
    "plot_1day_coiled.cluster.scale(5)\n",
    "\n",
    "# Begin computations:\n",
    "results = plot_1day_coiled.map(dates_2022[:5], outputdir=\"./\", ancillary_images=ancillary_images)\n",
    "\n",
    "#for f, d in zip(results, dates_2022):\n",
    "#    if f is not None:\n",
    "#        f.savefig(\"./animation_images/COWVR_STPH8_L2_EDR_V9.0_\" + d + \".jpg\")\n",
    "#    del f\n",
    "\n",
    "for f in results:\n",
    "    print(f[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce115b-7c3d-4074-a385-418eba117ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
